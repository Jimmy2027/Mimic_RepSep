\begin{abstract}
    Machine Learning (ML) has become more and more popular in the medical domain over the past years.
While supervised machine learning has received the most attention, unsupervised learning has great potential since there is more data available for the training of the models.
Especially when leveraging the multi-modal nature of most clinical data, self-supervised learning can provide results comparable to supervised methods.
    Multi-modal unsupervised methods have been tested extensively on toy-datasets like MNIST \cite{lecun-mnisthandwrittendigit-2010, thomas_gener-ELBO, wu2018multimodal} and CelebA \cite{liu2015faceattributes, thomas_gener-ELBO, wu2018multimodal} but to the best of our knowledge have never been applied to medical data, for direct applications such as disease classification and image generation.
In this article, we apply a method for self-supervised training proposed in \cite{thomas_gener-ELBO} to the MIMIC-CXR Database \cite{johnson2019mimic} and evaluate it in an exhaustive list of experiments.
\end{abstract}

